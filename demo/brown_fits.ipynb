{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Brown Sample with Prospector and Dynesty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interactive version of the demo demonstrating `dynesty` usage on the Brown et al. (2014) sample of galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's set up some environmental dependencies. These just make the numerics easier and adjust some of the plotting defaults to make things more legible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time, sys, os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re-defining plotting defaults\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import gridspec\n",
    "rcParams.update({'xtick.major.pad': '7.0'})\n",
    "rcParams.update({'xtick.major.size': '7.5'})\n",
    "rcParams.update({'xtick.major.width': '1.5'})\n",
    "rcParams.update({'xtick.minor.pad': '7.0'})\n",
    "rcParams.update({'xtick.minor.size': '3.5'})\n",
    "rcParams.update({'xtick.minor.width': '1.0'})\n",
    "rcParams.update({'ytick.major.pad': '7.0'})\n",
    "rcParams.update({'ytick.major.size': '7.5'})\n",
    "rcParams.update({'ytick.major.width': '1.5'})\n",
    "rcParams.update({'ytick.minor.pad': '7.0'})\n",
    "rcParams.update({'ytick.minor.size': '3.5'})\n",
    "rcParams.update({'ytick.minor.width': '1.0'})\n",
    "rcParams.update({'xtick.color': 'k'})\n",
    "rcParams.update({'ytick.color': 'k'})\n",
    "rcParams.update({'font.size': 30})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prospector** utilizes three main packages:\n",
    "- **fsps**, which governs the fundamental stellar population synthesis models (via the **python-fsps** package),\n",
    "- **sedpy**, which contains some routines for computing projecting spectra onto filter bandpasses, and\n",
    "- **prospect**, which is where the likelihood evaluations, parameter priors, and posterior sampling takes place.\n",
    "\n",
    "Let's import those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fsps\n",
    "import sedpy\n",
    "import prospect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to initialize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prospect.models import model_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall or meta-parameters controlling how the fit is done are stored in the ``run_params`` dictionary, which is a mix of options\n",
    "  1. defined in the parameter file\n",
    "  2. specified at the command line (if not running in interactive mode.)\n",
    "\n",
    "Let's load them from the parameter file and look at them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clargs = {'param_file': 'brownseds_agn_params.py'}\n",
    "run_params = model_setup.get_run_params(argv='brownseds_agn_params.py', **clargs)\n",
    "print(run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will be composed of four components:\n",
    "- an **stellar population synthesis (SPS)** model for the underlying physical parameters,\n",
    "- an underlying **statistical model** composed of a set of parameters, priors, etc., \n",
    "- a **noise model** for the underlying calibration vector, and\n",
    "- a set of **observations** we are trying to fit.\n",
    "\n",
    "See the input parameter file for additional info on the specific parameters we are initializing here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SPS model specified in the ``load_obs`` method of the parameter file can be one of several different types, corresponding to different SFH parameterizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load sps model\n",
    "sps = model_setup.load_sps(**run_params)\n",
    "print(sps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we set the noise models to ``None``, which means that the default simple $\\chi^2$ style likelihood will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load noise model (none)\n",
    "spec_noise, phot_noise = model_setup.load_gp(**run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model object keeps track of the fit parameters and their priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load parameter model\n",
    "model = model_setup.load_model(**run_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `obs` dictionary contains all our observational data, from which we are attempting to infer posterior PDFs for the parameters.  Guidelines for units and what keys must be in the `obs` dictionary can be found in the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# demo data (generated from the script)\n",
    "obs = model_setup.load_obs(**run_params)\n",
    "print(run_params['objname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've initialized the components of our model, we need to define how we want to compare our model to the data by establishing the appropriate **likelihood**. In most cases, this will simply be a function of the **spectral likelihood** and a **photometric likelihood** such that\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = f(\\mathcal{L}_{\\textrm{spec}}, \\mathcal{L}_{\\textrm{phot}}) \\quad .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming our errors are Normal (i.e. Gaussian), the log-likelihoods for each component are extremely straightforward to define and can be imported directly from Prospector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from prospect.likelihood import lnlike_spec, lnlike_phot, write_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we choose to combine these likelihoods might vary depending on the particulars of our data. For the demo, our likelihood function for our model parameters $\\boldsymbol{\\theta}$ is just\n",
    "\n",
    "$$\n",
    "\\ln\\mathcal{L}(\\boldsymbol{\\theta}) = \\ln\\mathcal{L}_{\\textrm{spec}}(\\boldsymbol{\\theta}) + \\ln\\mathcal{L}_{\\textrm{phot}}(\\boldsymbol{\\theta}) \\quad .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lnprobfn(theta):\n",
    "    \"\"\"Given a parameter vector, a dictionary of observational data \n",
    "    and a model object, return the ln of the posterior. \n",
    "    This requires that an sps object (and if using spectra \n",
    "    and gaussian processes, a GP object) be instantiated.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate prior probability and exit if not within prior\n",
    "    lnp_prior = model.prior_product(theta, nested=True)\n",
    "    if not np.isfinite(lnp_prior):\n",
    "        return -np.infty\n",
    "        \n",
    "    # Generate mean model\n",
    "    try:\n",
    "        spec, phot, x = model.mean_model(theta, obs, sps=sps)\n",
    "    except(ValueError):\n",
    "        return -np.infty\n",
    "    vectors = {}  # This would be used for noise model weight functions\n",
    "\n",
    "    # Calculate likelihoods\n",
    "    lnp_spec = lnlike_spec(spec, obs=obs, spec_noise=spec_noise)\n",
    "    lnp_phot = lnlike_phot(phot, obs=obs, phot_noise=phot_noise)\n",
    "\n",
    "    return lnp_prior + lnp_phot + lnp_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Prospector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at our model/data to get a sense of what we're dealing with and what we're fitting for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Free params:', model.free_params\n",
    "print 'Fixed params:', model.fixed_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `z_fraction` is a vector that includes 5 parameters (as the non-parametric SFH), this gives us a total of 15 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SED Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see what our model and data look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wspec = sps.wavelengths  # *restframe* spectral wavelengths\n",
    "a = 1.0 + model.params.get('zred', 0.0)  # cosmological redshifting\n",
    "\n",
    "# photometric effective wavelengths\n",
    "wphot = np.array([f.wave_effective for f in obs['filters']])\n",
    "\n",
    "# initial parameters\n",
    "initial_theta = model.rectify_theta(model.initial_theta)\n",
    "\n",
    "# generate model\n",
    "out_init = model.mean_model(initial_theta, obs, sps=sps) \n",
    "mspec_init, mphot_init, mextra_init = out_init\n",
    "\n",
    "# establish bounds\n",
    "xmin, xmax = np.min(wphot) * 0.8, np.max(wphot) / 0.8\n",
    "temp = np.interp(np.linspace(xmin, xmax, 10000), wspec * a, mspec_init)\n",
    "ymin, ymax = temp.min() * 0.8, temp.max() / 0.8\n",
    "\n",
    "# set up figure\n",
    "figure(figsize=(16, 8))\n",
    "\n",
    "# plot model + data\n",
    "loglog(wspec * a, mspec_init, label='Model spectrum', \n",
    "       lw=0.7, color='navy', alpha=0.7)\n",
    "errorbar(wphot, mphot_init, label='Model photometry', \n",
    "         marker='s', markersize=10, alpha=0.8, ls='', lw=3,\n",
    "         markerfacecolor='none', markeredgecolor='blue', \n",
    "         markeredgewidth=3)\n",
    "errorbar(wphot, obs['maggies'], yerr=obs['maggies_unc'], \n",
    "         label='Observed photometry',\n",
    "         marker='o', markersize=10, alpha=0.8, ls='', lw=3,\n",
    "         ecolor='red', markerfacecolor='none', markeredgecolor='red', \n",
    "         markeredgewidth=3)\n",
    "\n",
    "# plot filters\n",
    "for f in obs['filters']:\n",
    "    w, t = f.wavelength.copy(), f.transmission.copy()\n",
    "    while t.max() > 1:\n",
    "        t /= 10.\n",
    "    t = 0.1 * (ymax - ymin) * t + ymin\n",
    "    loglog(w, t, lw=3, color='gray', alpha=0.7)\n",
    "\n",
    "# prettify\n",
    "xlabel('Wavelength [A]')\n",
    "ylabel('Flux Density [maggies]')\n",
    "xlim([xmin, xmax])\n",
    "ylim([ymin, ymax])\n",
    "legend(loc='best', fontsize=20)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got all the objects set up, we can begin sampling from the posterior using **Nested Sampling**. Prospector by default uses **emcee**, but here we will use [**dynesty**](https://github.com/joshspeagle/dynesty). For nested sampling we need to define a prior transfrom function. This is easy with the prior objects in Prospector, where a prior_transform method is defined by the model object. We also need to make sure that the prior probability calculation in the posterior probability function is appropriate for nested sampling (note the `nested=True` option in `model.prior_product` in the `lnprobfn` above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prior_transform(u):        \n",
    "    \"\"\"Simple wrapper for the model prior transform.\"\"\"\n",
    "    \n",
    "    return model.prior_transform(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that creating a new model with FSPS is somewhat time-intensive, but once the relevant model(s) have been loaded they are subsequently stored in cache so similar models can be generated much more quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets import **dynesty**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dynesty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling in Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dynesty supports parallel operations through the use of a user-provided pool. Let's set up a pool now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import ipyparallel\n",
    "import ipyparallel as ipp\n",
    "rc = ipp.Client()  # create a client (running MPI)\n",
    "dview = rc[:]  # create a `DirectView` object\n",
    "dview.use_dill();  # use `dill` for advanced pickling\n",
    "nprocs = len(rc.ids)  # number of MPI processes available\n",
    "\n",
    "print(rc.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "# import environment\n",
    "import time, sys, os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import fsps\n",
    "import sedpy\n",
    "import prospect\n",
    "from prospect.models import model_setup\n",
    "from prospect.likelihood import lnlike_spec, lnlike_phot, write_log\n",
    "from prospect.io import write_results\n",
    "import dynesty\n",
    "\n",
    "# set up model\n",
    "clargs = {'param_file': 'brownseds_agn_params.py'}\n",
    "run_params = model_setup.get_run_params(argv='brownseds_agn_params.py', **clargs)\n",
    "sps = model_setup.load_sps(**run_params)\n",
    "spec_noise, phot_noise = model_setup.load_gp(**run_params)\n",
    "model = model_setup.load_model(**run_params)\n",
    "obs = model_setup.load_obs(**run_params)\n",
    "\n",
    "# set up posterior\n",
    "def lnprobfn(theta):\n",
    "    \"\"\"Given a parameter vector, a dictionary of observational data \n",
    "    and a model object, return the ln of the posterior. \n",
    "    This requires that an sps object (and if using spectra \n",
    "    and gaussian processes, a GP object) be instantiated.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate prior probability and exit if not within prior\n",
    "    lnp_prior = model.prior_product(theta, nested=True)\n",
    "    if not np.isfinite(lnp_prior):\n",
    "        return -np.infty\n",
    "        \n",
    "    # Generate mean model\n",
    "    try:\n",
    "        spec, phot, x = model.mean_model(theta, obs, sps=sps)\n",
    "    except(ValueError):\n",
    "        return -np.infty\n",
    "    vectors = {}  # This would be used for noise model weight functions\n",
    "\n",
    "    # Calculate likelihoods\n",
    "    lnp_spec = lnlike_spec(spec, obs=obs, spec_noise=spec_noise)\n",
    "    lnp_phot = lnlike_phot(phot, obs=obs, phot_noise=phot_noise)\n",
    "\n",
    "    return lnp_prior + lnp_phot + lnp_spec\n",
    "\n",
    "# set up prior transform\n",
    "def prior_transform(u):\n",
    "    \"\"\"Simple wrapper for the model prior transform.\"\"\"\n",
    "    \n",
    "    return model.prior_transform(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pool(object):\n",
    "    \"\"\"A simple wrapper for `dview`.\"\"\"\n",
    "    \n",
    "    def __init__(self, dview):\n",
    "        self.dview = dview\n",
    "        \n",
    "    def map(self, function, tasks):\n",
    "        return self.dview.map_sync(function, tasks)\n",
    "\n",
    "# define our pool\n",
    "pool = Pool(dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Nested Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to standard nested sampling, `dynesty` also implements **dynamic nested sampling**, which allows live points to be allocated dynamically. By default, the dynamic nested sampler in dynesty prioritizes posterior inference over evidence (80% posterior vs 20% evidence weighting). It also includes automated stopping criteria to measure posterior and evidence convergence, although by default only the posterior contributions are considered (i.e. 100% posterior vs 0% evidence weighting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize sampler\n",
    "dsampler = dynesty.DynamicNestedSampler(lnprobfn, prior_transform, model.ndim,  # necessary inputs\n",
    "                                        bound='multi', sample='rwalk',  # how we want to bound/sample\n",
    "                                        pool=pool, queue_size=nprocs,  # parallel stuff\n",
    "                                        update_interval=model.ndim*nprocs*1.,  # update interval\n",
    "                                        **{'walks': 50})  # increase number of walks to be more conservative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial batch\n",
    "tstart = time.time()  # time it\n",
    "dsampler.run_nested(dlogz_init=0.01, nlive_init=200, maxbatch=0, use_stop=False)\n",
    "dresult = dsampler.results\n",
    "ndur = time.time() - tstart\n",
    "\n",
    "print('done dynesty (initial, parallel) in {0}s'.format(ndur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# subsequent sampling\n",
    "tstart = time.time()  # time it\n",
    "dsampler.run_nested(nlive_batch=200, wt_kwargs={'pfrac': 1.0, 'maxfrac': 0.6})\n",
    "dresult = dsampler.results\n",
    "ddur = time.time() - tstart\n",
    "\n",
    "print('done dynesty (dynamic, parallel) in {0}s'.format(ddur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the dynesty result object as a pickle  \n",
    "import pickle\n",
    "from prospect.io import write_results\n",
    "outroot = \"{0}_{1}\".format(run_params['outfile'], int(time.time()))\n",
    "with open(outroot + '_dns.pkl', 'w') as f:\n",
    "    pickle.dump(dresult, f)\n",
    "partext = write_results.paramfile_string(**run_params)\n",
    "\n",
    "# Write the model as a pickle\n",
    "write_results.write_model_pickle(outroot + '_model', model, powell=None,\n",
    "                                 paramfile_text=partext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dynesty import plotting as dyplot\n",
    "\n",
    "labels = ['logmass', 'z_frac1', 'z_frac2', 'z_frac3', 'z_frac4',\n",
    "          'z_frac5', 'dust2', 'logzsol', 'dust_index', 'dust1_fraction',\n",
    "          'duste_qpah', 'duste_gamma', 'duste_umin', 'fagn', 'agn_tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot run\n",
    "rfig, rax = dyplot.runplot(dresult, logplot=True)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot trace and save figure\n",
    "fig, axes = subplots(model.ndim, 2, figsize=(20, model.ndim*5))\n",
    "fig, axes = dyplot.traceplot(dresult, labels=labels, show_titles=True,\n",
    "                             title_kwargs={'fontsize': 28, 'y': 1.05},\n",
    "                             fig=(fig, axes))\n",
    "tight_layout()\n",
    "fig.savefig(outroot+'_trace.png', bbox_inches='tight')\n",
    "close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot corner and save figure\n",
    "fig, axes = subplots(model.ndim, model.ndim, figsize=(model.ndim*5, model.ndim*5))\n",
    "fig, axes = dyplot.cornerplot(dresult, smooth=10, color='blue', labels=labels,\n",
    "                              show_titles=True, title_kwargs={'y': 1.05},\n",
    "                              fig=(fig, axes))\n",
    "fig.savefig(outroot+'_corner.png', bbox_inches='tight')\n",
    "close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's just take a look at a random model drawn from our chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly chosen parameters from chain\n",
    "idx = np.random.choice(dresult['niter'], p=np.exp(dresult['logwt'] - dresult['logz'][-1]))\n",
    "theta = dresult['samples'][idx]\n",
    "\n",
    "# generate model\n",
    "mspec, mphot, mextra = model.mean_model(theta, obs, sps=sps)\n",
    "\n",
    "# establish bounds\n",
    "xmin, xmax = wphot.min() * 0.8, wphot.max() / 0.8\n",
    "temp = np.interp(np.linspace(xmin, xmax, 10000), wspec * a, mspec)\n",
    "ymin, ymax = temp.min() * 0.8, temp.max() / 0.8\n",
    "\n",
    "# set up figure\n",
    "figure(figsize=(16, 8))\n",
    "\n",
    "# plot data and model\n",
    "loglog(wspec * a, mspec, label='Model spectrum',\n",
    "       lw=0.7, color='navy', alpha=0.7)\n",
    "errorbar(wphot, mphot, label='Model photometry',\n",
    "         marker='s', markersize=10, alpha=0.8, ls='', lw=3, \n",
    "         markerfacecolor='none', markeredgecolor='blue', \n",
    "         markeredgewidth=3)\n",
    "errorbar(wphot, obs['maggies'], yerr=obs['maggies_unc'], \n",
    "         label='Observed photometry', ecolor='red', \n",
    "         marker='o', markersize=10, ls='', lw=3, alpha=0.8, \n",
    "         markerfacecolor='none', markeredgecolor='red', \n",
    "         markeredgewidth=3)\n",
    "\n",
    "# plot filters\n",
    "for f in obs['filters']:\n",
    "    w, t = f.wavelength.copy(), f.transmission.copy()\n",
    "    while t.max() > 1:\n",
    "        t /= 10.\n",
    "    t = 0.1 * (ymax-ymin) * t + ymin\n",
    "    loglog(w, t, lw=3, color='gray', alpha=0.7)\n",
    "\n",
    "xlabel('Wavelength [A]')\n",
    "ylabel('Flux Density [maggies]')\n",
    "xlim([xmin, xmax])\n",
    "ylim([ymin, ymax])\n",
    "legend(loc='best', fontsize=20)\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
